{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting data to integer\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(\"int\")\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the data type of the columns\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking balance of diabetic vs not diabetic \n",
    "display(df[\"Diabetes_binary\"].value_counts())\n",
    "\n",
    "#significant imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data for later use\n",
    "\n",
    "X = df.copy()\n",
    "X = X.drop(columns=\"Diabetes_binary\")\n",
    "y = df[\"Diabetes_binary\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF Evaluation\n",
    "### - Evaluation of Initial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Variance Inflation Factor to assess usefulness of each column of the original df\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# VIF dataframe for original df\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"Features\"] = X.columns \n",
    "  \n",
    "# calculating VIF for each feature \n",
    "vif_df[\"Calculated VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))] \n",
    "  \n",
    "print(vif_df)\n",
    "\n",
    "# Following columns appear to distort the data: CholCheck, BMI, Veggies, AnyHealthcare, GenHlth, Age, Education, Income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created df where less useful columns are dropped\n",
    "\n",
    "df_drop_cols = df.drop(columns=[ \"CholCheck\", \"BMI\", \"Veggies\", \"AnyHealthcare\", \"GenHlth\", \"Age\", \"Education\", \"Income\"])\n",
    "df_drop_cols.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Test Data\n",
    "### - Test Train for Initial DF and Updated DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test and train data for initial df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 10)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated X to contain only useful features\n",
    "X = df_drop_cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test and train data for updated df\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X,y, random_state = 10)\n",
    "X_train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Scaling Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling original features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled_orig_array = scaler.transform(X_train)\n",
    "X_test_scaled_orig_array = scaler.transform(X_test)\n",
    "\n",
    "#scaling updated features (less useful columns removed)\n",
    "scaler = StandardScaler().fit(X_train2)\n",
    "X_train2_scaled_upd_array = scaler.transform(X_train2)\n",
    "\n",
    "#updating X train, X test and X train2(less features) from array to df for both\n",
    "\n",
    "X_train_scaled_orig = pd.DataFrame(X_train_scaled_orig_array, columns = X_train.columns)\n",
    "display(X_train_scaled_orig.head())\n",
    "\n",
    "X_test_scaled_upd = pd.DataFrame(X_test_scaled_orig_array, columns = X_train.columns)\n",
    "display(X_test_scaled_upd.head())\n",
    "\n",
    "X_train2_scaled_upd = pd.DataFrame(X_train2_scaled_upd_array, columns = X_train2.columns)\n",
    "display(X_train2_scaled_upd.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - VIF for Scaled Features (for Training Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIF for Scaled data\n",
    "# calculating VIF for scaled trained orig features \n",
    "vif_df[\"Calculated Scaled VIF\"] = [variance_inflation_factor(X_train_scaled_orig.values, i) for i in range(len(X_train_scaled_orig.columns))]\n",
    "\n",
    "# calculating VIF for scaled trained updated features\n",
    "vif_scaled_df = pd.DataFrame()\n",
    "vif_scaled_df[\"Scaled Trained Features\"] = X_train2_scaled_upd.columns\n",
    "vif_scaled_df[\"Scaled Trained VIF\"] = [variance_inflation_factor(X_train2_scaled_upd.values, i) for i in range(len(X_train2_scaled_upd.columns))] \n",
    "  \n",
    "print(vif_df, end=\"\\n\\n\\n\")\n",
    "print(vif_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Modeling - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  - Logistic Regression on Raw Data & Score (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using logistic regression model first as a baseline\n",
    "# original raw data\n",
    "\n",
    "classifier = LogisticRegression(max_iter=500)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# score for training data (evaluates how well the model performs on the training data)\n",
    "print(f\"Training Data Accuracy Score: {classifier.score(X_train, y_train)}\")\n",
    "\n",
    "#score for test data (evaluates model's ability to make predictions on unseen data)\n",
    "print(f\"Test Data Accuracy Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating predictions using the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Checking balanced accuracy due to the significant imbalance of the data\n",
    "print(f\"Balanced Accuracy Score (score is more useful given data imbalance): {balanced_accuracy_score(y_test, y_pred)}\")\n",
    "\n",
    "#not great, barely better than random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  - Logistic Regression on Scaled Data & Score (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using logistic regression model on scaled X_train_scaled_orig and X_train2_scaled_upd\n",
    "\n",
    "classifier.fit(X_train_scaled_orig, y_train)\n",
    "y_pred_scaled = classifier.predict(X_test_scaled_upd)\n",
    "                                  \n",
    "# checking balanced accuracy for scaled data\n",
    "print(f\"Balanced Accuracy Score (score is more useful given data imbalance): {balanced_accuracy_score(y_test, y_pred_scaled)}\")\n",
    "\n",
    "#not great, barely better than random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocess Data II - Undersampling Data\n",
    "\n",
    "     Due to significant imbalance and score, I don't think it is worth attempting RandomForest model unless the data's balance is improved. Next step undersamples the data. I selected undersampling rather than oversampling due to the larger balance (163932) being over 6x larger than the smaller balance (26328). The smaller balance is plenty and may predict better than attempting to predict using a significant amount of synthetic data compared to the actual data available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - RandomUnderSampler Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomUnderSampler from imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Instantiate a RandomUnderSampler instance\n",
    "rus = RandomUnderSampler(random_state=63)\n",
    "\n",
    "# Fitting the training data\n",
    "X_rus_resampled, y_rus_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Fitting the scaled training data\n",
    "X_rus_resampled_scaled, y_rus_resampled_scaled = rus.fit_resample(X_train_scaled_orig, y_train)\n",
    "\n",
    "display(y_rus_resampled.value_counts())\n",
    "display(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - ClusterCentroids Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "# Instantiate instance\n",
    "cc = ClusterCentroids(random_state=63, n_init = \"auto\")\n",
    "\n",
    "# Fitting the training data\n",
    "X_cc_resampled, y_cc_resampled = cc.fit_resample(X_train, y_train)\n",
    "\n",
    "# Fitting the scaled training data\n",
    "X_cc_resampled_scaled, y_cc_resampled_scaled = cc.fit_resample(X_train_scaled_orig, y_train)\n",
    "\n",
    "display(y_cc_resampled.value_counts())\n",
    "display(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - EditedNearestNeighbors Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "\n",
    "# Instantiate instance\n",
    "enn = EditedNearestNeighbours(n_neighbors = 6, sampling_strategy = \"auto\")\n",
    "\n",
    "# Fitting the training data\n",
    "X_enn_resampled, y_enn_resampled = enn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Fitting the scaled training data\n",
    "X_enn_resampled_scaled, y_enn_resampled_scaled = enn.fit_resample(X_train_scaled_orig, y_train)\n",
    "\n",
    "display(y_enn_resampled.value_counts())\n",
    "display(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - RandomForest \\*\\*\\*LEFT OFF\\*\\*\\*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviewing the randomforest model's accuracy using classification report\n",
    "# raw_model = RandomForestClassifier(random_state = 32, n_estimators = 100).fit(X_train, y_train)\n",
    "# y_predict_rfc_raw_test = raw_model.predict(X_test)\n",
    "# print(classification_report(y_test, y_predict_rfc_raw_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using confusion_matrix\n",
    "# true neg  | false posi\n",
    "# false neg | true pos\n",
    "\n",
    "#print(confusion_matrix(y_test, y_predict_rfc_raw_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(balanced_accuracy_score(y_test, y_predict_rfc_raw_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore below - Scratch Paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling data using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smt = SMOTE(random_state = 42)\n",
    "X_train_sm, y_train_sm = smt.fit_resample(X_train,y_train)\n",
    "X_test_sm, y_test_sm = smt.fit_resample(X_test,y_test)\n",
    "\n",
    "#chatgpt suggested Counter to review the scale\n",
    "print(Counter(y_train_sm))\n",
    "print(Counter(y_test_sm))\n",
    "\n",
    "#checked the original prediction from randomforest model)\n",
    "print(Counter(y_predict_rfc_raw_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train test data for the smote values\n",
    "\n",
    "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_train_sm, y_train_sm, random_state = 15)\n",
    "X_train_smote2, X_test_smote2, y_train_smote2, y_test_smote2 = train_test_split(X_test_sm, y_test_sm, random_state = 15)\n",
    "\n",
    "smt_model = RandomForestClassifier(random_state = 32, n_estimators = 100).fit(X_train_smote, y_train_smote)\n",
    "smt_model2 = RandomForestClassifier(random_state = 32, n_estimators = 100).fit(X_train_smote2, y_train_smote2)\n",
    "\n",
    "y_predicted_smt = smt_model.predict(X_test_smote)\n",
    "y_predicted_smt2 = smt_model2.predict(X_test_smote2)\n",
    "\n",
    "\n",
    "# for the train data\n",
    "print(classification_report(y_train_smote, y_predicted_smt))\n",
    "\n",
    "# for the test data\n",
    "print(classification_report(y_train_smote2, y_predicted_smt2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(balanced_accuracy_score(y_train_smote, y_predicted_smt))\n",
    "display(balanced_accuracy_score(y_train_smote2, y_predicted_smt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempting to use randomized search estimator - creating the required parameters first)\n",
    "param_grid = {\n",
    "    'n_neighbors': np.arange(1,20,2),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': np.arange(1, 500)\n",
    "}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the randomized search estimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_clf = RandomizedSearchCV(random_tuned_model, param_grid, random_state=0, verbose=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
