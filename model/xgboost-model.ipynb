{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in data\n",
    "csv_path = \"../data/diabetes_binary_health_indicators_BRFSS2015.csv\"\n",
    "data = pd.read_csv(csv_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker',\n",
       "       'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies',\n",
       "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
       "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
       "       'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary\n",
       "0.0    218334\n",
       "1.0     35346\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Diabetes_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `vif_removal_priority()` from `utils.py` to return a list of features that should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Education', 29.584451146273683],\n",
       " ['CholCheck', 22.245439651302405],\n",
       " ['AnyHealthcare', 18.1501738000634],\n",
       " ['BMI', 14.7838897768036]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils as fu\n",
    "\n",
    "fu.vif_removal_priority(X=data, threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Diabetes_binary\", \"Education\", \"CholCheck\", \"AnyHealthcare\", \"BMI\"])\n",
    "y = data[\"Diabetes_binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HighBP', 'HighChol', 'Smoker', 'Stroke', 'HeartDiseaseorAttack',\n",
       "       'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'NoDocbcCost',\n",
       "       'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary\n",
       "0.0    163677\n",
       "1.0     26583\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the distinct values from y\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base `RandomForestClassifier()` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a RandomForestClassifier instance\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the traning data to the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for original scaled testing features\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `RandomUnderSampler()` for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary\n",
       "0.0    26583\n",
       "1.0    26583\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a RandomUnderSampler instance\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Fit the training data to the random undersampler model\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Count distinct values for the resampled target data\n",
    "y_undersampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a new `RandomForestClassifier()` model with undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a RandomForestClassifier() model\n",
    "model_undersampled = RandomForestClassifier()\n",
    "\n",
    "# Fit the undersampled data the new model\n",
    "model_undersampled.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "# Predict labels for oversampled testing features\n",
    "y_pred_undersampled = model_undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `RandomOverSampler()` for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary\n",
       "0.0    163677\n",
       "1.0    163677\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import RandomOverSampler from imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Instantiate a RandomOversampler instance\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit the training data to the `RandomOverSampler` model\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Count distinct values\n",
    "y_oversampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a new `RandomForestClassifier()` model with oversampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new RandomForestClassier model\n",
    "model_oversampled = RandomForestClassifier()\n",
    "\n",
    "# Fit the oversampled data the new model\n",
    "model_oversampled.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "# Predict labels for oversampled testing features\n",
    "y_pred_oversampled = model_oversampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - Original Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.17      0.24      8763\n",
      "           0       0.88      0.96      0.92     54657\n",
      "\n",
      "    accuracy                           0.85     63420\n",
      "   macro avg       0.63      0.56      0.58     63420\n",
      "weighted avg       0.81      0.85      0.82     63420\n",
      "\n",
      "------------------------------------------------------\n",
      "Classification Report - Undersampled Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.75      0.39      8763\n",
      "           0       0.94      0.67      0.78     54657\n",
      "\n",
      "    accuracy                           0.68     63420\n",
      "   macro avg       0.61      0.71      0.59     63420\n",
      "weighted avg       0.85      0.68      0.73     63420\n",
      "\n",
      "------------------------------------------------------\n",
      "Classification Report - Oversampled Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.36      0.33      8763\n",
      "           0       0.89      0.86      0.88     54657\n",
      "\n",
      "    accuracy                           0.80     63420\n",
      "   macro avg       0.60      0.61      0.60     63420\n",
      "weighted avg       0.81      0.80      0.80     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification reports\n",
    "print(f\"Classification Report - Original Data\")\n",
    "print(classification_report(y_test, y_pred, labels=[1,0]))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Classification Report - Undersampled Data\")\n",
    "print(classification_report(y_test, y_pred_undersampled, labels=[1,0]))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Classification Report - Oversampled Data\")\n",
    "print(classification_report(y_test, y_pred_oversampled, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the dataset into an optimized data structure called Dmatrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Define data_dmatrix\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating an `XGBoost()` classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model accuracy score: 0.8487\n"
     ]
    }
   ],
   "source": [
    "# Import XGBClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Declare parameters\n",
    "params = {\n",
    "            'objective':'binary:logistic',\n",
    "            'max_depth': 4,\n",
    "            'alpha': 10,\n",
    "            'learning_rate': .8,\n",
    "            'n_estimators':200\n",
    "        }\n",
    "            \n",
    "              \n",
    "# Instantiate the classifier \n",
    "xgb_clf = XGBClassifier(**params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "clf_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Check accuracy score\n",
    "\n",
    "print('XGBoost model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.12      0.20      8763\n",
      "           0       0.87      0.98      0.93     54657\n",
      "\n",
      "    accuracy                           0.86     63420\n",
      "   macro avg       0.70      0.55      0.56     63420\n",
      "weighted avg       0.82      0.86      0.82     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Classification Report - XGBoost\")\n",
    "print(classification_report(y_test, clf_pred, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - XGBoost Oversampled\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.78      0.42      8763\n",
      "           0       0.95      0.70      0.80     54657\n",
      "\n",
      "    accuracy                           0.71     63420\n",
      "   macro avg       0.62      0.74      0.61     63420\n",
      "weighted avg       0.86      0.71      0.75     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier \n",
    "xgb_clf_over = XGBClassifier(**params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_over.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "# Make predictions on test data\n",
    "clf_pred_over = xgb_clf_over.predict(X_test)\n",
    "\n",
    "print(f\"Classification Report - XGBoost Oversampled\")\n",
    "print(classification_report(y_test, clf_pred_over, labels=[1,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report - XGBoost Undersampled\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.79      0.42      8763\n",
      "           0       0.95      0.68      0.79     54657\n",
      "\n",
      "    accuracy                           0.70     63420\n",
      "   macro avg       0.62      0.74      0.61     63420\n",
      "weighted avg       0.86      0.70      0.74     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the classifier \n",
    "xgb_clf_under = XGBClassifier(**params)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_under.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "# Make predictions on test data\n",
    "clf_pred_under = xgb_clf_under.predict(X_test)\n",
    "\n",
    "print(f\"Classification Report - XGBoost Undersampled\")\n",
    "print(classification_report(y_test, clf_pred_under, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `GridSearchCV()` to find best set of hyperparameters\n",
    "### XGBoost GridSearch Oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [1, 0.1, 0.01],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'n_estimators': [350, 450, 550]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_over_grid = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_over = GridSearchCV(xgb_over_grid, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search_over.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "# Make predictions on test data\n",
    "grid_pred_over = grid_search_over.predict(X_test)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search_over.best_params_)\n",
    "print(\"Best score: \", grid_search_over.best_score_)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Classification Report - XGBoost GridSearch Oversampled\")\n",
    "print(classification_report(y_test, grid_pred_over, labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bapej\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 81 is smaller than n_iter=100. Running 81 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters:  {'subsample': 0.7, 'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.1}\n",
      "Best score:  0.7799049357279475\n",
      "------------------------------------------------------\n",
      "Classification Report - XGBoost RandomSearch Oversampled\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.73      0.42      8763\n",
      "           0       0.94      0.73      0.82     54657\n",
      "\n",
      "    accuracy                           0.73     63420\n",
      "   macro avg       0.62      0.73      0.62     63420\n",
      "weighted avg       0.85      0.73      0.77     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_distributions = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'n_estimators': [100, 250, 400]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=100,  # Number of parameter settings that are sampled\n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    random_state=42  # Ensuring reproducibility\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV object to the training data\n",
    "random_search.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "# Make predictions on test data\n",
    "predictions = random_search.predict(X_test)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Classification Report - XGBoost RandomSearch Oversampled\")\n",
    "print(classification_report(y_test, predictions, labels=[1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CLF V2 accuracy score: 0.5126\n",
      "------------------------------------------------------\n",
      "Classification Report - XGBoost CLF V2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.93      0.35      8763\n",
      "           0       0.98      0.44      0.61     54657\n",
      "\n",
      "    accuracy                           0.51     63420\n",
      "   macro avg       0.59      0.69      0.48     63420\n",
      "weighted avg       0.87      0.51      0.57     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Declare parameters\n",
    "params_v2 = {\n",
    "            'objective':'binary:logistic',\n",
    "            'scale_pos_weight':4,\n",
    "            'subsample': 0.7,\n",
    "            'max_depth': 7,\n",
    "            'alpha': 10,\n",
    "            'learning_rate': .1,\n",
    "            'n_estimators':400\n",
    "        }\n",
    "            \n",
    "              \n",
    "# Instantiate the classifier \n",
    "xgb_clf_v2 = XGBClassifier(**params_v2)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_clf_v2.fit(X_oversampled, y_oversampled)\n",
    "\n",
    "# Make predictions on test data\n",
    "clf_pred_v2 = xgb_clf_v2.predict(X_test)\n",
    "\n",
    "# Check accuracy score\n",
    "\n",
    "print('XGBoost CLF V2 accuracy score: {0:0.4f}'. format(accuracy_score(y_test, clf_pred_v2)))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Classification Report - XGBoost CLF V2\")\n",
    "print(classification_report(y_test, clf_pred_v2, labels=[1,0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost GridSearch Undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best set of hyperparameters:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 400, 'subsample': 1}\n",
      "Best score:  0.7358274629529846\n",
      "------------------------------------------------------\n",
      "Classification Report - XGBoost GridSearch Undersampled\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.81      0.42      8763\n",
      "           0       0.96      0.68      0.79     54657\n",
      "\n",
      "    accuracy                           0.70     63420\n",
      "   macro avg       0.62      0.74      0.61     63420\n",
      "weighted avg       0.86      0.70      0.74     63420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1],\n",
    "    'n_estimators': [100, 250, 400]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model object\n",
    "xgb_under_grid = xgb.XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_under = GridSearchCV(xgb_under_grid, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search_under.fit(X_undersampled, y_undersampled)\n",
    "\n",
    "# Make predictions on test data\n",
    "grid_pred_under = grid_search_under.predict(X_test)\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search_under.best_params_)\n",
    "print(\"Best score: \", grid_search_under.best_score_)\n",
    "print(\"------------------------------------------------------\")\n",
    "print(f\"Classification Report - XGBoost GridSearch Undersampled\")\n",
    "print(classification_report(y_test, grid_pred_under, labels=[1,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
